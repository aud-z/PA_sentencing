{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Adjust the code for the clean \"DOF\" issue\n",
    "2. Fix the issue -- adjust the isues with the at_risk date\n",
    "2. Fix the \"Free Time Issue\"\n",
    "3. Make sure that the final exported dataframe is at the id_variable, dos level\n",
    "4. Document (in Word Doc or even at the end of this file the logic used at each step of the process and why decisions where made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ongoing Questions:\n",
    "insert any lingering questions here\n",
    "1. Should we subset the data to where dof < OR equal to dos or JUST keep data that is strictly less then (dof < dos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (19,29,45,46,48,49,50,51,52,53,59,63,64,66) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#this jupyter notebook is essentially the same as the \"recidivism-check\" notebook, just cleaned up a bit (hence the name)\n",
    "#import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "#get the folder path for this data\n",
    "pa_sentencing_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "#read in the correct data file (need to read in this file because of the additional columns it has)\n",
    "psc_trimmed = pd.read_csv(os.path.join(pa_sentencing_path, \"Project\", \"data\", \"PSC_data_trimmed_v1.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this code chunk below only once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this only once to create an in-memory database for the data (should speed up retrieval times)\n",
    "\n",
    "#read in the trimmed dataset\n",
    "# psc_trimmed = pd.read_csv(os.path.join(pa_sentencing_path, \"Project\", \"data\", \"Main.csv\"),\n",
    "# usecols = ['JPR_ID','id_variable','dof','dos','prs','INC_SANCTION_EXISTS','JP_CC_BUG','JP_MIN','JP_LIFE_DEATH','OFN_LIFE_DEATH'])\n",
    "\n",
    "# conn = sqlite3.connect(\"psc_data2.db\")\n",
    "# cur = conn.cursor()\n",
    "# ## Creating Table\n",
    "# cur.execute('''CREATE TABLE IF NOT EXISTS raw_data  \n",
    "#         (JPR_ID\tINTEGER, \n",
    "#         prs TEXT, \n",
    "#         INC_SANCTION_EXISTS TEXT, \n",
    "#         dof TEXT,\t\n",
    "#         dos TEXT, \n",
    "#         JP_MIN TEXT,\t\n",
    "#         OFN_LIFE_DEATH TEXT,\n",
    "#         id_variable INTEGER, \n",
    "#         JP_LIFE_DEATH TEXT,\n",
    "#         JP_CC_BUG TEXT)''')\n",
    "\n",
    "# insert_query = \"\"\" INSERT INTO raw_data (\n",
    "#    JPR_ID,\t\n",
    "#    prs,\t\n",
    "#    INC_SANCTION_EXISTS,\n",
    "#    dof,\t\n",
    "#    dos,\t\n",
    "#    JP_MIN,\t\n",
    "#    OFN_LIFE_DEATH,\t\n",
    "#    id_variable,\t\n",
    "#    JP_LIFE_DEATH,\t\n",
    "#    JP_CC_BUG)\n",
    "#    VALUES (?,?,?,?,?,?,?,?,?,?)\"\"\"\n",
    "# raw_list = psc_trimmed.values.tolist()    \n",
    "# cur.executemany(insert_query, raw_list)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import datetime\n",
    "# import sqlite3\n",
    "# def load_data():\n",
    "#     \"\"\" Read the sqlite database, from the file \".db\" into a pandas dataframe\n",
    "#     Returns:\n",
    "#         pd.DataFrame : a dataframe \n",
    "#     \"\"\"    \n",
    "#     conn = sqlite3.connect(\"psc_data2.db\")\n",
    "#     df_raw = pd.read_sql_query(\"SELECT * FROM raw_data\", conn)\n",
    "#     return(df_raw)\n",
    "\n",
    "# df_tbl_db = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying the original loaded data to a working data frame to use and compare with later\n",
    "#df = df_tbl_db.copy() #if accessing the database\n",
    "\n",
    "df = psc_trimmed.copy() # if accessing the psc_trimmed file directly\n",
    "\n",
    "\n",
    "#change column names to uppercase\n",
    "df.columns = df.columns.str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPR_ID</th>\n",
       "      <th>OFF_SEX</th>\n",
       "      <th>OFF_RACE</th>\n",
       "      <th>DOFAGE</th>\n",
       "      <th>OTN</th>\n",
       "      <th>OFN_TITLE</th>\n",
       "      <th>OFN_COUNT</th>\n",
       "      <th>OFN_LABEL</th>\n",
       "      <th>OFN_GRADE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>...</th>\n",
       "      <th>STAT_MIN</th>\n",
       "      <th>DISPOSITION</th>\n",
       "      <th>CONFORMITY</th>\n",
       "      <th>REASON_ONE</th>\n",
       "      <th>REASON_TWO</th>\n",
       "      <th>REASON_THREE</th>\n",
       "      <th>MORE_REASONS</th>\n",
       "      <th>PRS_MANUAL</th>\n",
       "      <th>PRS_LAPSING</th>\n",
       "      <th>PRS_NONLAPSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640001</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>36.689938</td>\n",
       "      <td>H182628-5</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Corruption of Minors - when of a sexual nature</td>\n",
       "      <td>M-1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>Nolo Contendere</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642480</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>18.540726</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>DUI - M-2</td>\n",
       "      <td>M-2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Neg. Guilty Plea</td>\n",
       "      <td>Standard/Mandatory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660434</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>36.914442</td>\n",
       "      <td>H3618344</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>DUI - M-2</td>\n",
       "      <td>M-2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Non-Neg. Guilty Plea</td>\n",
       "      <td>Standard/Mandatory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628940</td>\n",
       "      <td>M</td>\n",
       "      <td>Black</td>\n",
       "      <td>22.297057</td>\n",
       "      <td>G0816126</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Simple Assault</td>\n",
       "      <td>M-2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Neg. Guilty Plea</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594048</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>40.087611</td>\n",
       "      <td>H240127-6</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>DUI - M-1</td>\n",
       "      <td>M-1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Standard/Mandatory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   JPR_ID OFF_SEX OFF_RACE     DOFAGE        OTN  OFN_TITLE OFN_COUNT  \\\n",
       "0  640001       F    White  36.689938  H182628-5         18         1   \n",
       "1  642480       M    White  18.540726          0         75         1   \n",
       "2  660434       M    White  36.914442   H3618344         75         1   \n",
       "3  628940       M    Black  22.297057   G0816126         18         1   \n",
       "4  594048       M    White  40.087611  H240127-6         75         1   \n",
       "\n",
       "                                        OFN_LABEL OFN_GRADE  GRADE  ...  \\\n",
       "0  Corruption of Minors - when of a sexual nature       M-1      4  ...   \n",
       "1                                       DUI - M-2       M-2      3  ...   \n",
       "2                                       DUI - M-2       M-2      3  ...   \n",
       "3                                  Simple Assault       M-2      3  ...   \n",
       "4                                       DUI - M-1       M-1      4  ...   \n",
       "\n",
       "   STAT_MIN           DISPOSITION          CONFORMITY REASON_ONE REASON_TWO  \\\n",
       "0        30       Nolo Contendere            Standard        NaN        NaN   \n",
       "1        12      Neg. Guilty Plea  Standard/Mandatory        NaN        NaN   \n",
       "2        12  Non-Neg. Guilty Plea  Standard/Mandatory        NaN        NaN   \n",
       "3        12      Neg. Guilty Plea            Standard        NaN        NaN   \n",
       "4        30                   NaN  Standard/Mandatory        NaN        NaN   \n",
       "\n",
       "  REASON_THREE  MORE_REASONS  PRS_MANUAL PRS_LAPSING PRS_NONLAPSING  \n",
       "0          NaN         False         NaN           0              0  \n",
       "1          NaN         False         NaN           0              0  \n",
       "2          NaN         False         NaN           0              0  \n",
       "3          NaN         False         NaN           0              0  \n",
       "4          NaN         False         NaN           1              1  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date strings to datetime variable\n",
    "df[['DOF','DOS']] = df[['DOF','DOS']].apply(pd.to_datetime,format=\"%d %b %y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting out the just the year from the date to be used later \n",
    "df['DOF_YEAR'] = pd.DatetimeIndex(df['DOF']).year\n",
    "df['DOS_YEAR'] = pd.DatetimeIndex(df['DOS']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum date of offense in the dataset is: 1984-11-14 00:00:00\n",
      "The maximum date of offense in the dataset is: 2020-05-08 00:00:00\n",
      "The minimum date of sentencing in the dataset is: 2001-01-01 00:00:00\n",
      "The maximum date of sentencing in the dataset is: 2019-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#checking the range of values for the DOF and DOS variables\n",
    "print(\"The minimum date of offense in the dataset is: {}\".format(df[[\"DOF\"]].min()[0]))\n",
    "print(\"The maximum date of offense in the dataset is: {}\".format(df[[\"DOF\"]].max()[0]))\n",
    "print(\"The minimum date of sentencing in the dataset is: {}\".format(df[[\"DOS\"]].min()[0]))\n",
    "print(\"The maximum date of sentencing in the dataset is: {}\".format(df[[\"DOS\"]].max()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: As shown in the above code chunk, there **isn't** anamolous behavior in the date ranges (i.e. a date in the year 1909 or 2090) for the date of offense (DOF) or date of sentence (DOS) variables -- therefore, an additional date correction was **not** applied in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean DOS > DOF\n",
    "\n",
    "Note: group offense by ID_VAR, JPR_ID, MIN(DOF) to get the first DOF associated for a single JPR_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15,965 rows with missing DOFs in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# df_no_missing = df[df['DOF'].notnull()]\n",
    "\n",
    "# #subset to just those rows where DOF is missing\n",
    "# dof_missing = df[df['DOF'].isnull()]\n",
    "# not needed\n",
    "\n",
    "#df[:20].head() \n",
    "\n",
    "#count how many values of DOF are missing in the original dataset\n",
    "dof_missing = df[df['DOF'].isnull()]\n",
    "\n",
    "\n",
    "print(\"There are {:,} rows with missing DOFs in the dataset.\".format(len(dof_missing)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group offense by ID_VAR, JPR_ID, MIN(DOF) to get the first DOF associated for a single JPR_ID -- fix issue with missing DOF\n",
    "# for name, group in df.groupby(\"JPR_ID\"):\n",
    "#     #only applies if there is more than one charge \n",
    "\n",
    "#     #number of charges in a group\n",
    "#     num_chargs = len(group)\n",
    "\n",
    "#     if num_chargs > 1:\n",
    "#         list_of_dof = group['DOF'].tolist()\n",
    "#         min_dof = min(list_of_dof)\n",
    "\n",
    "#         #check if nas are in the list and ONLY change the DOF to MIN IF the DOF is missing\n",
    "#         updated_dof  = []\n",
    "#         for x in list_of_dof:\n",
    "#             if pd.isnull(x):\n",
    "#                 updated_dof.append(min_dof)\n",
    "#             else:\n",
    "#                 updated_dof.append(x)\n",
    "  \n",
    "#         #only reassign IF for that row the DOF is missing\n",
    "#         df.loc[df[\"JPR_ID\"] == name, 'DOF'] = updated_dof\n",
    "\n",
    "#at the JPR_ID level we only want ONE DOF because becuase we don't want to take into account DOF's that occur\n",
    "#BEFORE the DOS (associated with the JPR_ID) as an instance of recidivism. -- each JPR_ID should have only ONE DOS\n",
    "# for name, group in df[:20].groupby(\"JPR_ID\"):  \n",
    "#     #only applies if there is more than one charge \n",
    "\n",
    "#     #number of charges in a group\n",
    "#     num_chargs = len(group)\n",
    "\n",
    "#     if num_chargs > 1:\n",
    "#         list_of_dof = group['DOF'].tolist()\n",
    "#         min_dof = min(list_of_dof)\n",
    "#         print(list_of_dof)\n",
    "#         print(min_dof)\n",
    "\n",
    "#         updated_dof = [min_dof for x in list_of_dof]\n",
    "\n",
    "#         #reassign the DOF to the minimum for that JPR_ID\n",
    "#         df.loc[df[\"JPR_ID\"] == name, 'DOF'] = updated_dof\n",
    "\n",
    "\n",
    "# df[:20].head()[[\"JPR_ID\", \"DOF\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the data just to where the number of charges for a given JPR_ID is > 1\n",
    "# counts_by_jpr_id = df.groupby([\"JPR_ID\"]).agg({\"DOF\": \"count\"})\n",
    "\n",
    "# multiple_chargs_jpr_ids = list(counts_by_jpr_id.loc[counts_by_jpr_id[\"DOF\"] > 1].index)\n",
    "\n",
    "# #print(len(multiple_chargs_jpr_ids))\n",
    "\n",
    "# test_df = df[df[\"JPR_ID\"].isin(multiple_chargs_jpr_ids)]\n",
    "\n",
    "#print(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.head()[[\"JPR_ID\", \"DOF\"]]\n",
    "\n",
    "#want the earliest offense for a given JPR_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at the JPR_ID level we only want ONE DOF because becuase we don't want to take into account DOF's that occur\n",
    "#BEFORE the DOS (associated with the JPR_ID) as an instance of recidivism. -- each JPR_ID should have only ONE DOS\n",
    "\n",
    "#test_df[\"NEW_DOF\"] = test_df.groupby([\"JPR_ID\"])[\"DOF\"].transform(\"min\")\n",
    "\n",
    "\n",
    "#test_df.head()[[\"JPR_ID\", \"DOF\", \"NEW_DOF\"]]\n",
    "#one_test_example = test_df.loc[test_df[\"JPR_ID\"] == 658826][[\"DOF\", \"NEW_DOF\"]] \n",
    "# one_test_example[\"NEW_DOF\"] = one_test_example.groupby([\"JPR_ID\"])[\"DOF\"].transform(\"min\")\n",
    "# one_test_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1**: Make sure that we are only looking at the **minimum** value for the DOF across all of the charges associated with **one** JPR_ID. This is the procedure because we don't wan't to count a DOF as an instance of recidivism if it occurs BEFORE the date of sentencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at the JPR_ID level we only want ONE DOF because becuase we don't want to take into account DOF's that occur\n",
    "#BEFORE the DOS (associated with the JPR_ID) as an instance of recidivism. -- each JPR_ID should have only ONE DOS\n",
    "\n",
    "df[\"NEW_DOF\"] = df.groupby([\"JPR_ID\"])[\"DOF\"].transform(\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPR_ID</th>\n",
       "      <th>DOF</th>\n",
       "      <th>NEW_DOF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640001</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>2000-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642480</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>1999-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660434</td>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>2000-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628940</td>\n",
       "      <td>2000-06-26</td>\n",
       "      <td>2000-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594048</td>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>2000-10-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JPR_ID        DOF    NEW_DOF\n",
       "0  640001 2000-04-01 2000-04-01\n",
       "1  642480 1999-12-31 1999-12-31\n",
       "2  660434 2000-12-23 2000-12-23\n",
       "3  628940 2000-06-26 2000-06-26\n",
       "4  594048 2000-10-15 2000-10-15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()[[\"JPR_ID\", \"DOF\", \"NEW_DOF\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning, there are 11,785 (0.454381%) rows with missing DOFs in the dataset.\n"
     ]
    }
   ],
   "source": [
    "dof_missing = df[df['NEW_DOF'].isnull()]\n",
    "\n",
    "percent_missing = len(dof_missing)/len(df)\n",
    "print(\"After cleaning, there are {:,} ({:%}) rows with missing DOFs in the dataset.\".format(len(dof_missing), percent_missing))\n",
    "\n",
    "\n",
    "\n",
    "#random testing code here\n",
    "#df.head()\n",
    "# test = [pd.NaT, 1,2, 3]\n",
    "# updated_dof = [x for x in test if pd.isnull(x)] \n",
    "# updated_dof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2**: Subset the data to just include those rows where NEW_DOF <= DOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before DOF <= DOS correction there were 2,593,636 rows and after cleaning there were 2,581,813 rows. A change of 11,823.\n"
     ]
    }
   ],
   "source": [
    "#make sure the sentencing \n",
    "before_length = len(df)\n",
    "df = df[df.NEW_DOF <= df.DOS] #should this be <= ?\n",
    "after_length = len(df)\n",
    "\n",
    "print(\"Before DOF <= DOS correction there were {:,} rows and after cleaning there were {:,} rows. A change of {:,}.\".format(before_length, after_length, before_length - after_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(psc_trimmed), len(df), len(psc_trimmed) - len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Missing PRS Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to just the id variables with a PRS score missing\n",
    "# id_varswith_prsmissing= set(df[df.prs.isnull()].id_variable)\n",
    "# #remove id vars with missing PRS\n",
    "# df_prs_notaffected = df[~df.id_variable.isin(id_varswith_prsmissing)]\n",
    "# #reassign to working dataframe\n",
    "# df = df_prs_notaffected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before PRS correction there were 2,581,813 rows and after cleaning there were 2,581,787 rows. A change of 26.\n"
     ]
    }
   ],
   "source": [
    "# PRS SCORE CLEANING - removes only the rows where the PRS score is missing not the entire individual \n",
    "before_length = len(df)\n",
    "df = df.loc[df['PRS'].notnull()]\n",
    "after_length = len(df)\n",
    "\n",
    "print(\"Before PRS correction there were {:,} rows and after cleaning there were {:,} rows. A change of {:,}.\".format(before_length, after_length, before_length - after_length))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean JP CC Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the id variables with jp_bug\n",
    "id_varswith_jpbug= set(df[df.JP_CC_BUG=='Y'].ID_VARIABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning all the rows associated with the jp bugs to a seperate dataframe \n",
    "df_with_jpbug=  df[df.ID_VARIABLE.isin(id_varswith_jpbug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Removing the rows of these that are beyond 2016(rows in the future that are affected by the JP_CC_BUG)\n",
    "df_jp_bug_cleaned = df_with_jpbug[df.DOS_YEAR<2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the rows associated with id_vars in the original dataframe that is not associated with the bug\n",
    "df_jpbug_notaffected = df[~df.ID_VARIABLE.isin(id_varswith_jpbug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoining the rows affected by the JP_CC_bug after cleaning them to the rows not affected by the bug\n",
    "df_cleaned_1 = pd.concat([df_jpbug_notaffected,df_jp_bug_cleaned])  #new wor\n",
    "\n",
    "df = df_cleaned_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the JP_CC_BUG correction there are 2,562,426 rows. \n"
     ]
    }
   ],
   "source": [
    "after_length = len(df)\n",
    "\n",
    "print(\"After the JP_CC_BUG correction there are {:,} rows. \".format(after_length))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement At Risk Date Calculation Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO ADD THIS TO TAKE CARE OF TIME SERVED AND POTENTIALLY DIFFERENT JP_MIN VALS\n",
    "\n",
    "IF INC_SANCTION_EXISTS = ‘N’: do nothing \n",
    "ELIF INC_SANCTION_EXISTS on at least 1 charge:\n",
    "If DOS is the same across all charges:\n",
    "Get MAX(JP_MIN) across charges for this JPR_ID\n",
    "If DOS is different across charges:\n",
    "Use JP_MIN + MAX(DOS) - [ MAX(DOS) - MIN(DOS) ] to get time incarcerated \n",
    "Should this be: JP_MIN + (MAX(DOS) + [ MAX(DOS) - MIN(DOS) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 338,885 entries in the dataset missing a JP_MIN value.\n",
      "There are 338,811 entries in the dataset missing a  ADJ_JPMIN value.\n"
     ]
    }
   ],
   "source": [
    "#Fix Issues with the missing JP_MIN\n",
    "num_missing_jp_min = len(df.loc[pd.isna(df[\"JP_MIN\"])]) #[[\"JPR_ID\", \"JP_MIN\"]]\n",
    "print(\"There are {:,} entries in the dataset missing a JP_MIN value.\".format(num_missing_jp_min))\n",
    "\n",
    "df[\"ADJ_JPMIN\"] = df.groupby([\"JPR_ID\"])[\"JP_MIN\"].transform(\"min\")\n",
    "\n",
    "#df.head()[[\"JPR_ID\", \"JP_MIN\", \"ADJ_JPMIN\"]]\n",
    "\n",
    "num_missing_jp_min = len(df.loc[pd.isna(df[\"ADJ_JPMIN\"])]) #[[\"JPR_ID\", \"JP_MIN\"]]\n",
    "print(\"There are {:,} entries in the dataset missing a  ADJ_JPMIN value.\".format(num_missing_jp_min))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I keep running into an issue with the below where the kernel keeps dying for me :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_at_risk_date(row):\n",
    "    #need to account for REALLY large JP_MIN values\n",
    "    #20 years in days = 10 * 365\n",
    "    \n",
    "    upper_limit = 20.0 * 365.0\n",
    "    \n",
    "    num_days_in_month = 30.0\n",
    "    \n",
    "    #if offense has a life or death flag, set their at_risk_date abritarily large\n",
    "    if row['OFN_LIFE_DEATH'] == \"Y\":\n",
    "        at_risk_date = pd.to_datetime('9999-12-31')\n",
    "\n",
    "    #if they were not incarcerated, then their at risk date is just their date of offense\n",
    "    if row[\"INC_SANCTION_EXISTS\"] == \"N\":\n",
    "        at_risk_date = row['NEW_DOF']\n",
    "    \n",
    "    #if they were incarcerated, look at the below logic to determine their at-risk date\n",
    "    else:\n",
    "\n",
    "        #if row[\"ADJ_JPMIN\"] < upper_limit:\n",
    "\n",
    "        if row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.notna(row['ADJ_JPMIN']):\n",
    "            at_risk_date = row['DOS'] + pd.Timedelta(days = row['ADJ_JPMIN'])\n",
    "        \n",
    "        elif row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.notna(row['INCMIN']):\n",
    "            at_risk_date = row['DOS'] + pd.Timedelta(days = row['INCMIN'] * num_days_in_month)\n",
    "\n",
    "        #these are individuals who have life and death sentences\n",
    "        #their inc_end date = 12/31/9999 -- see codebook for more details\n",
    "        # elif row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.isna(row['INCMIN']) and pd.isna(row['ADJ_JPMIN']):\n",
    "        #     at_risk_date = row[\"INC_END\"]\n",
    "\n",
    "        # elif row[\"INC_SANCTION_EXISTS\"] == \"N\":\n",
    "        #     at_risk_date = row['NEW_DOF']\n",
    "\n",
    "        else:\n",
    "            at_risk_date = row['INC_END']\n",
    "\n",
    "        #else:\n",
    "           # at_risk_date = row[\"INC_END\"]\n",
    "    \n",
    "    return at_risk_date\n",
    "\n",
    "\n",
    "# df[\"AT_RISK_DT\"] = np.where(\n",
    "#     df['INC_SANCTION_EXISTS'] == \"Y\" and pd.notna(df['JP_MIN']), 1, 0)\n",
    "\n",
    "# test = df[:2000]\n",
    "# #apply the function to the data (row by row)\n",
    "# test[\"AT_RISK_DT\"] = test.apply(create_at_risk_date, axis = 1)\n",
    "\n",
    "#  #adjust so that the times do not include minutes and seconds\n",
    "# test[\"AT_RISK_DT\"] = pd.to_datetime(test[\"AT_RISK_DT\"]).dt.date\n",
    "\n",
    "# # #inspect the results\n",
    "# test[['ID_VARIABLE', 'JPR_ID',\"JP_MIN\", \"INCMIN\", \"INC_END\", \"ADJ_JPMIN\", \"INC_SANCTION_EXISTS\", \"DOS\", \"NEW_DOF\", \"AT_RISK_DT\"]]\n",
    "\n",
    "#test = df[:2000]\n",
    "#apply the function to the data (row by row)\n",
    "df[\"AT_RISK_DT\"] = df.apply(create_at_risk_date, axis = 1)\n",
    "\n",
    " #adjust so that the times do not include minutes and seconds\n",
    "df[\"AT_RISK_DT\"] = pd.to_datetime(df[\"AT_RISK_DT\"]).dt.date\n",
    "\n",
    "# #inspect the results\n",
    "df[['ID_VARIABLE', 'JPR_ID',\"JP_MIN\", \"INCMIN\", \"INC_END\", \"ADJ_JPMIN\", \"INC_SANCTION_EXISTS\", \"DOS\", \"NEW_DOF\", \"AT_RISK_DT\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[:20][['ID_VARIABLE', 'JPR_ID',\"JP_MIN\", \"INC_SANCTION_EXISTS\", \"DOS\", \"NEW_DOF\", \"AT_RISK_DT\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"AT_RISK_DT\"] = np.where(\n",
    "#     (df['INC_SANCTION_EXISTS'] == \"Y\") & (pd.notna(df['ADJ_JPMIN'])), (df['DOS'] + pd.Timedelta(days = df['ADJ_JPMIN'])) , df[\"DOF\"]) \n",
    "\n",
    "# df[\"AT_RISK_DT\"] = np.where(\n",
    "#     (df['INC_SANCTION_EXISTS'] == \"Y\"), pd.to_datetime(df['DOS'] + pd.Timedelta(days = df['ADJ_JPMIN'])).dt.date, pd.to_datetime(\"9999-99-99\")) \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "# df.head()[['ID_VARIABLE', 'JPR_ID',\"JP_MIN\", \"ADJ_JPMIN\", \"INC_SANCTION_EXISTS\", \"DOS\", \"NEW_DOF\", \"AT_RISK_DT\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Next DOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the data\n",
    "df = df.sort_values(by = [\"ID_VARIABLE\", \"NEW_DOF\"])\n",
    "\n",
    "#set the sorted at_risk vals equal to a new df\n",
    "#final_next_dof = at_risk_calc_sorted\n",
    "\n",
    "#shift the data up by one to create the new vaariable \"NEXT_DOF\"\n",
    "df['NEXT_DOF'] = df.groupby(['ID_VARIABLE'])['NEW_DOF'].shift(-1).dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for \"Free Time\" -- Make Sure Individuals in the Dataset Have Enough Free Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals whose **first*** offense results in an AT_RISK DATE of 2017 or greater = remove these individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just want to remove those whose last next_dof > 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TIME TO RECIDIVATE AND RECIDIVSM VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract the next_dof and at_risk_dt variables\n",
    "df['TIME_TO_RECIDIVATE'] = pd.to_datetime(df['NEXT_DOF']) - pd.to_datetime(df['AT_RISK_DT'])\n",
    "\n",
    "#update the time to recidivate column to JUST be the number of days as an integer/float\n",
    "df['TIME_TO_RECIDIVATE'] = df['TIME_TO_RECIDIVATE'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of days in  years\n",
    "three_years_in_days = float(3) * 365.0  \n",
    "five_years_in_days = float(5) * 365.0  \n",
    "\n",
    "#JUDICIAL-PROCEEDING LEVEL RECIDIVISM\n",
    "#final_next_dof[\"RECIDIVISM_3Y\"] = final_next_dof.apply(create_recidivism_var, years = 3, axis = 1)\n",
    "\n",
    "df[\"RECIDIVISM_3Y\"] = np.where(\n",
    "    df['TIME_TO_RECIDIVATE'] <= three_years_in_days, 1, 0)\n",
    "\n",
    "df[\"RECIDIVISM_5Y\"] = np.where(\n",
    "    df['TIME_TO_RECIDIVATE'] <= five_years_in_days, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export The Results to CSV (MAKE SURE DATA IS AT THE DOS, ID_VARIABLE LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the Results to a CSV\n",
    "\n",
    "#double check that the \n",
    "\n",
    "#export the dataframe with the recidivism variables to a new dataframe\n",
    "output_path = os.path.join(pa_sentencing_path, \"Project\", \"data\", \"recidivsm_dataset.csv\")\n",
    "\n",
    "df.to_csv(output_path) #export the final results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
