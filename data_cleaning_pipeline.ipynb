{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To-do:\n",
    "1. Adjust the code for the clean \"DOF\" issue\n",
    "2. Fix the issue -- adjust the isues with the at_risk date\n",
    "2. Fix the \"Free Time Issue\"\n",
    "3. Make sure that the final exported dataframe is at the id_variable, dos level\n",
    "4. Document (in Word Doc or even at the end of this file the logic used at each step of the process and why decisions where made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ongoing Questions:\n",
    "insert any lingering questions here\n",
    "1. Should we subset the data to where dof < OR equal to dos or JUST keep data that is strictly less then (dof < dos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (23,342,351,535) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Volumes/DATA/PA_SENTENCING_PROJECT/Home/tobi/PA_sentencing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this jupyter notebook is essentially the same as the \"recidivism-check\" notebook, just cleaned up a bit (hence the name)\n",
    "#import required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "#get the folder path for this data\n",
    "pa_sentencing_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this code chunk below only once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this only once to create an in-memory database for the data (should speed up retrieval times)\n",
    "\n",
    "#read in the trimmed dataset\n",
    "psc_trimmed = pd.read_csv(os.path.join(pa_sentencing_path, \"Project\", \"data\", \"Main.csv\"),\n",
    "usecols = ['JPR_ID','id_variable','dof','dos','prs','INC_SANCTION_EXISTS','JP_CC_BUG','JP_MIN','JP_LIFE_DEATH','OFN_LIFE_DEATH'])\n",
    "\n",
    "conn = sqlite3.connect(\"psc_data2.db\")\n",
    "cur = conn.cursor()\n",
    "## Creating Table\n",
    "cur.execute('''CREATE TABLE IF NOT EXISTS raw_data  \n",
    "        (JPR_ID\tINTEGER, \n",
    "        prs TEXT, \n",
    "        INC_SANCTION_EXISTS TEXT, \n",
    "        dof TEXT,\t\n",
    "        dos TEXT, \n",
    "        JP_MIN TEXT,\t\n",
    "        OFN_LIFE_DEATH TEXT,\n",
    "        id_variable INTEGER, \n",
    "        JP_LIFE_DEATH TEXT,\n",
    "        JP_CC_BUG TEXT)''')\n",
    "\n",
    "insert_query = \"\"\" INSERT INTO raw_data (\n",
    "   JPR_ID,\t\n",
    "   prs,\t\n",
    "   INC_SANCTION_EXISTS,\n",
    "   dof,\t\n",
    "   dos,\t\n",
    "   JP_MIN,\t\n",
    "   OFN_LIFE_DEATH,\t\n",
    "   id_variable,\t\n",
    "   JP_LIFE_DEATH,\t\n",
    "   JP_CC_BUG)\n",
    "   VALUES (?,?,?,?,?,?,?,?,?,?)\"\"\"\n",
    "raw_list = psc_trimmed.values.tolist()    \n",
    "cur.executemany(insert_query, raw_list)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import sqlite3\n",
    "def load_data():\n",
    "    \"\"\" Read the sqlite database, from the file \".db\" into a pandas dataframe\n",
    "    Returns:\n",
    "        pd.DataFrame : a dataframe \n",
    "    \"\"\"    \n",
    "    conn = sqlite3.connect(\"psc_data2.db\")\n",
    "    df_raw = pd.read_sql_query(\"SELECT * FROM raw_data\", conn)\n",
    "    return(df_raw)\n",
    "\n",
    "df_tbl_db = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying the original loaded data to a working data frame to use and compare with later\n",
    "df = df_tbl_db.copy() #if accessing the database\n",
    "\n",
    "df = psc_trimmed.copy() # if accessing the psc_trimmed file directly\n",
    "\n",
    "\n",
    "#change column names to uppercase\n",
    "df.columns = df.columns.str.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPR_ID</th>\n",
       "      <th>PRS</th>\n",
       "      <th>INC_SANCTION_EXISTS</th>\n",
       "      <th>DOF</th>\n",
       "      <th>DOS</th>\n",
       "      <th>JP_MIN</th>\n",
       "      <th>OFN_LIFE_DEATH</th>\n",
       "      <th>ID_VARIABLE</th>\n",
       "      <th>JP_LIFE_DEATH</th>\n",
       "      <th>JP_CC_BUG</th>\n",
       "      <th>DOF_YEAR</th>\n",
       "      <th>DOS_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640001</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>2001-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642480</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1157226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660434</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>2001-04-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1467650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628940</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2000-06-26</td>\n",
       "      <td>2001-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1746031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594048</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JPR_ID PRS INC_SANCTION_EXISTS        DOF        DOS  JP_MIN  \\\n",
       "0  640001   0                   N 2000-04-01 2001-06-12     NaN   \n",
       "1  642480   0                   Y 1999-12-31 2001-12-03     2.0   \n",
       "2  660434   0                   Y 2000-12-23 2001-04-26     2.0   \n",
       "3  628940   0                   N 2000-06-26 2001-05-22     NaN   \n",
       "4  594048   1                   Y 2000-10-15 2001-01-03   183.0   \n",
       "\n",
       "  OFN_LIFE_DEATH  ID_VARIABLE JP_LIFE_DEATH JP_CC_BUG  DOF_YEAR  DOS_YEAR  \n",
       "0            NaN      1904581           NaN       NaN    2000.0      2001  \n",
       "1            NaN      1157226           NaN       NaN    1999.0      2001  \n",
       "2            NaN      1467650           NaN       NaN    2000.0      2001  \n",
       "3            NaN      1746031           NaN       NaN    2000.0      2001  \n",
       "4            NaN      1374131           NaN       NaN    2000.0      2001  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data '954547200000000000' does not match format '%d %b %y' (match)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/conversion.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.conversion.datetime_to_datetime64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unrecognized value type: <class 'int'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-cd6375943d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#convert date strings to datetime variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DOF'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DOS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DOF'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'DOS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%d %b %y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 result = libreduction.compute_reduction(\n\u001b[0;32m--> 296\u001b[0;31m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 )\n\u001b[1;32m    298\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0munique_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mcache_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0mcache_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munique_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcache_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                     result, timezones = array_strptime(\n\u001b[0;32m--> 400\u001b[0;31m                         \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                     )\n\u001b[1;32m    402\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"%Z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"%z\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/tslibs/strptime.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data '954547200000000000' does not match format '%d %b %y' (match)"
     ]
    }
   ],
   "source": [
    "#convert date strings to datetime variable\n",
    "df[['DOF','DOS']] = df[['DOF','DOS']].apply(pd.to_datetime,format=\"%d %b %y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting out the just the year from the date to be used later \n",
    "df['DOF_YEAR'] = pd.DatetimeIndex(df['DOF']).year\n",
    "df['DOS_YEAR'] = pd.DatetimeIndex(df['DOS']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean DOS > DOF\n",
    "\n",
    "Note: group offense by ID_VAR, JPR_ID, MIN(DOF) to get the first DOF associated for a single JPR_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPR_ID</th>\n",
       "      <th>PRS</th>\n",
       "      <th>INC_SANCTION_EXISTS</th>\n",
       "      <th>DOF</th>\n",
       "      <th>DOS</th>\n",
       "      <th>JP_MIN</th>\n",
       "      <th>OFN_LIFE_DEATH</th>\n",
       "      <th>ID_VARIABLE</th>\n",
       "      <th>JP_LIFE_DEATH</th>\n",
       "      <th>JP_CC_BUG</th>\n",
       "      <th>DOF_YEAR</th>\n",
       "      <th>DOS_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640001</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>2001-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642480</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1157226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660434</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>2000-12-23</td>\n",
       "      <td>2001-04-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1467650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628940</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>2000-06-26</td>\n",
       "      <td>2001-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1746031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594048</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>2000-10-15</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JPR_ID PRS INC_SANCTION_EXISTS        DOF        DOS  JP_MIN  \\\n",
       "0  640001   0                   N 2000-04-01 2001-06-12     NaN   \n",
       "1  642480   0                   Y 1999-12-31 2001-12-03     2.0   \n",
       "2  660434   0                   Y 2000-12-23 2001-04-26     2.0   \n",
       "3  628940   0                   N 2000-06-26 2001-05-22     NaN   \n",
       "4  594048   1                   Y 2000-10-15 2001-01-03   183.0   \n",
       "\n",
       "  OFN_LIFE_DEATH  ID_VARIABLE JP_LIFE_DEATH JP_CC_BUG  DOF_YEAR  DOS_YEAR  \n",
       "0            NaN      1904581           NaN       NaN    2000.0      2001  \n",
       "1            NaN      1157226           NaN       NaN    1999.0      2001  \n",
       "2            NaN      1467650           NaN       NaN    2000.0      2001  \n",
       "3            NaN      1746031           NaN       NaN    2000.0      2001  \n",
       "4            NaN      1374131           NaN       NaN    2000.0      2001  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_no_missing = df[df['DOF'].notnull()]\n",
    "\n",
    "# #subset to just those rows where DOF is missing\n",
    "# dof_missing = df[df['DOF'].isnull()]\n",
    "# not needed\n",
    "\n",
    "df[:20].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPR_ID</th>\n",
       "      <th>PRS</th>\n",
       "      <th>INC_SANCTION_EXISTS</th>\n",
       "      <th>DOF</th>\n",
       "      <th>DOS</th>\n",
       "      <th>JP_MIN</th>\n",
       "      <th>OFN_LIFE_DEATH</th>\n",
       "      <th>ID_VARIABLE</th>\n",
       "      <th>JP_LIFE_DEATH</th>\n",
       "      <th>JP_CC_BUG</th>\n",
       "      <th>DOF_YEAR</th>\n",
       "      <th>DOS_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>640001</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>954547200000000000</td>\n",
       "      <td>2001-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1904581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>642480</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>946598400000000000</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1157226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660434</td>\n",
       "      <td>0</td>\n",
       "      <td>Y</td>\n",
       "      <td>977529600000000000</td>\n",
       "      <td>2001-04-26</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1467650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>628940</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>961977600000000000</td>\n",
       "      <td>2001-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1746031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>594048</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>971568000000000000</td>\n",
       "      <td>2001-01-03</td>\n",
       "      <td>183.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1374131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   JPR_ID PRS INC_SANCTION_EXISTS                 DOF        DOS  JP_MIN  \\\n",
       "0  640001   0                   N  954547200000000000 2001-06-12     NaN   \n",
       "1  642480   0                   Y  946598400000000000 2001-12-03     2.0   \n",
       "2  660434   0                   Y  977529600000000000 2001-04-26     2.0   \n",
       "3  628940   0                   N  961977600000000000 2001-05-22     NaN   \n",
       "4  594048   1                   Y  971568000000000000 2001-01-03   183.0   \n",
       "\n",
       "  OFN_LIFE_DEATH  ID_VARIABLE JP_LIFE_DEATH JP_CC_BUG  DOF_YEAR  DOS_YEAR  \n",
       "0            NaN      1904581           NaN       NaN    2000.0      2001  \n",
       "1            NaN      1157226           NaN       NaN    1999.0      2001  \n",
       "2            NaN      1467650           NaN       NaN    2000.0      2001  \n",
       "3            NaN      1746031           NaN       NaN    2000.0      2001  \n",
       "4            NaN      1374131           NaN       NaN    2000.0      2001  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group offense by ID_VAR, JPR_ID, MIN(DOF) to get the first DOF associated for a single JPR_ID -- fix issue with missing DOF\n",
    "for name, group in df[:20].groupby(\"JPR_ID\"):\n",
    "    #only applies if there is more than one charge \n",
    "    #number of charges in a group\n",
    "    num_chargs = len(group)\n",
    "    #print(name)\n",
    "    #print(group['DOF'])\n",
    "\n",
    "    if num_chargs > 1:\n",
    "        list_of_dof = group['DOF'].tolist()\n",
    "        min_dof = min(list_of_dof)\n",
    "\n",
    "        #check if nas are in the list and ONLY change the DOF to MIN IF the DOF is missing\n",
    "        updated_dof  = []\n",
    "        for x in list_of_dof:\n",
    "            if pd.isnull(x):\n",
    "                updated_dof.append(min_dof)\n",
    "            else:\n",
    "                updated_dof.append(x)\n",
    "  \n",
    "        #only reassign IF for that row the DOF is missing\n",
    "        df.loc[df[\"JPR_ID\"] == name, 'DOF'] = updated_dof\n",
    "\n",
    "\n",
    "        #print(min_dof)\n",
    "\n",
    "        #print(df.loc[df['JPR_ID'] == name])  #, 'DOF'])\n",
    "       # if df.loc[df['JPR_ID'] == name, 'DOF'].isnull():\n",
    "            #df.loc[df['JPR_ID'] == name, 'DOF'] = pd.nan #( set to a null value)\n",
    "\n",
    "    # else:\n",
    "    #     min_dof = min(group['DOF'])\n",
    "    #     df.loc[df['JPR_ID'] == name, 'DOF'] = min_dof\n",
    "\n",
    "df[:20].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NaT]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#random testing code here\n",
    "#df.head()\n",
    "# test = [pd.NaT, 1,2, 3]\n",
    "# updated_dof = [x for x in test if pd.isnull(x)] \n",
    "# updated_dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the sentencing \n",
    "df = df[df.DOF < df.DOS] #should this be <= ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Missing PRS Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset to just the id variables with a PRS score missing\n",
    "id_varswith_prsmissing= set(df[df.prs.isnull()].id_variable)\n",
    "#remove id vars with missing PRS\n",
    "df_prs_notaffected = df[~df.id_variable.isin(id_varswith_prsmissing)]\n",
    "#reassign to working dataframe\n",
    "df = df_prs_notaffected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean JP CC Bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the id variables with jp_bug\n",
    "id_varswith_jpbug= set(df[df.JP_CC_BUG=='Y'].id_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning all the rows associated with the jp bugs to a seperate dataframe \n",
    "df_with_jpbug=  df[df.id_variable.isin(id_varswith_jpbug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows of these that are beyond 2016(rows in the future that are affected by the JP_CC_BUG)\n",
    "df_jp_bug_cleaned = df_with_jpbug[df.dos_year<2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating the rows associated with id_vars in the original dataframe that is not associated with the bug\n",
    "df_jpbug_notaffected = df[~df.id_variable.isin(id_varswith_jpbug)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejoining the rows affected by the JP_CC_bug after cleaning them to the rows not affected by the bug\n",
    "df_cleaned_1 = pd.concat([df_jpbug_notaffected,df_jp_bug_cleaned])  #new wor\n",
    "\n",
    "df = df_cleaned_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement At Risk Date Calculation Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO ADD THIS TO TAKE CARE OF TIME SERVED AND POTENTIALLY DIFFERENT JP_MIN VALS\n",
    "\n",
    "IF INC_SANCTION_EXISTS = ‘N’: do nothing \n",
    "ELIF INC_SANCTION_EXISTS on at least 1 charge:\n",
    "If DOS is the same across all charges:\n",
    "Get MAX(JP_MIN) across charges for this JPR_ID\n",
    "If DOS is different across charges:\n",
    "Use JP_MIN + MAX(DOS) - [ MAX(DOS) - MIN(DOS) ] to get time incarcerated \n",
    "Should this be: JP_MIN + (MAX(DOS) + [ MAX(DOS) - MIN(DOS) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_at_risk_date(row):\n",
    "    #need to account for REALLY large JP_MIN values\n",
    "    #20 years in days = 10 * 365\n",
    "    upper_limit = 20.0 * 365.0\n",
    "    \n",
    "    num_days_in_month = 30.0\n",
    "\n",
    "    if row['JP_LIFE_DEATH'] == \"Y\":\n",
    "        at_risk_date = pd.to_datetime('9999-12-31')\n",
    "    \n",
    "    else:\n",
    "\n",
    "        if row[\"JP_MIN\"] < upper_limit:\n",
    "\n",
    "            if row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.notna(row['JP_MIN']):\n",
    "                at_risk_date = row['DOS'] + pd.Timedelta(days = row['JP_MIN'])\n",
    "            \n",
    "            elif row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.notna(row['INCMIN']):\n",
    "                at_risk_date = row['DOS'] + pd.Timedelta(days = row['INCMIN'] * num_days_in_month)\n",
    "\n",
    "            #these are individuals who have life and death sentences\n",
    "            #their inc_end date = 12/31/9999 -- see codebook for more details\n",
    "            elif row[\"INC_SANCTION_EXISTS\"] == \"Y\" and pd.isna(row['INCMIN']) and pd.isna(row['JP_MIN']) :\n",
    "                at_risk_date = row[\"INC_END\"]\n",
    "\n",
    "            elif row[\"INC_SANCTION_EXISTS\"] == \"N\":\n",
    "                at_risk_date = row['DOF']\n",
    "\n",
    "            else:\n",
    "                at_risk_date = row['INC_END']\n",
    "\n",
    "        else:\n",
    "            at_risk_date = row[\"INC_END\"]\n",
    "    \n",
    "    return at_risk_date\n",
    "\n",
    "\n",
    "#apply the function to the data (row by row)\n",
    "df[\"AT_RISK_DT\"] = df.apply(create_at_risk_date, axis = 1)\n",
    "\n",
    "#adjust so that the times do not include minutes and seconds\n",
    "df[\"AT_RISK_DT\"] = pd.to_datetime(df[\"AT_RISK_DT\"]).dt.date\n",
    "\n",
    "#inspect the results\n",
    "df[['ID_VARIABLE', 'JPR_ID',\"JP_MIN\", \"INC_SANCTION_EXISTS\", \"DOS\", \"DOF\", \"AT_RISK_DT\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for \"Free Time\" -- Make Sure Individuals in the Dataset Have Enough Free Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuals whose **first*** offense results in an AT_RISK DATE of 2017 or greater = remove these individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate Next DOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the data\n",
    "df = df.sort_values(by = [\"ID_VARIABLE\", \"DOF\"])\n",
    "\n",
    "#set the sorted at_risk vals equal to a new df\n",
    "#final_next_dof = at_risk_calc_sorted\n",
    "\n",
    "#shift the data up by one to create the new vaariable \"NEXT_DOF\"\n",
    "df['NEXT_DOF'] = df.groupby(['ID_VARIABLE'])['DOF'].shift(-1).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE TIME TO RECIDIVATE AND RECIDIVSM VARIABLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtract the next_dof and at_risk_dt variables\n",
    "df['TIME_TO_RECIDIVATE'] = pd.to_datetime(df['NEXT_DOF']) - pd.to_datetime(df['AT_RISK_DT'])\n",
    "\n",
    "#update the time to recidivate column to JUST be the number of days as an integer/float\n",
    "df['TIME_TO_RECIDIVATE'] = df['TIME_TO_RECIDIVATE'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of days in  years\n",
    "three_years_in_days = float(3) * 365.0  \n",
    "five_years_in_days = float(5) * 365.0  \n",
    "\n",
    "#JUDICIAL-PROCEEDING LEVEL RECIDIVISM\n",
    "#final_next_dof[\"RECIDIVISM_3Y\"] = final_next_dof.apply(create_recidivism_var, years = 3, axis = 1)\n",
    "\n",
    "df[\"RECIDIVISM_3Y\"] = np.where(\n",
    "    df['TIME_TO_RECIDIVATE'] <= three_years_in_days, 1, 0)\n",
    "\n",
    "df[\"RECIDIVISM_5Y\"] = np.where(\n",
    "    df['TIME_TO_RECIDIVATE'] <= five_years_in_days, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export The Results to CSV (MAKE SURE DATA IS AT THE DOS, ID_VARIABLE LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the Results to a CSV\n",
    "\n",
    "#double check that the \n",
    "\n",
    "#export the dataframe with the recidivism variables to a new dataframe\n",
    "output_path = os.path.join(pa_sentencing_path, \"Project\", \"data\", \"recidivsm_dataset.csv\")\n",
    "\n",
    "df.to_csv(output_path) #export the final results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
